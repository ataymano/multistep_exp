{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Learners"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Paul's stuff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Hashable, Sequence, Dict, Any\n",
    "import coba.random\n",
    "\n",
    "class Batched:\n",
    "    def __init__(self, delay: int, batchsize: int, learner):\n",
    "        self.learner = learner()\n",
    "        self.batchsize = batchsize\n",
    "        self.delay = delay\n",
    "        self.mem = {}\n",
    "\n",
    "        assert self.delay % self.batchsize == 0\n",
    "\n",
    "    def init(self):\n",
    "        self.learner.init()\n",
    "\n",
    "    @property\n",
    "    def family(self) -> str:\n",
    "        return \"Batched Learner\"\n",
    "\n",
    "    @property\n",
    "    def params(self) -> Dict[str,Any]:\n",
    "        return { \n",
    "                 **self.learner.params,\n",
    "                 **{ 'delay': self.delay, 'batchsize': self.batchsize },\n",
    "               }\n",
    "\n",
    "    def predict(self, key: int, context: Hashable, actions: Sequence[Hashable]) -> int:\n",
    "        \"\"\"Choose which action index to take.\"\"\"\n",
    "        return self.learner.predict(key, context, actions)\n",
    "\n",
    "    def learn(self, key: int, context: Hashable, action: Hashable, reward: float, probability: float) -> None:\n",
    "        \"\"\"Learn about the result of an action that was taken in a context.\"\"\"\n",
    "\n",
    "        self.mem[key] = { 'context': context,\n",
    "                          'action': action,\n",
    "                          'reward': reward,\n",
    "                          'prob': probability\n",
    "                        }\n",
    "\n",
    "        if len(self.mem) >= self.delay:\n",
    "            sumreward = 0\n",
    "            contexts = []\n",
    "            for key, values in self.mem.items():\n",
    "                sumreward += values['reward']\n",
    "                contexts.append((key, values))\n",
    "\n",
    "                if len(contexts) % self.batchsize == 0:\n",
    "                    for k, v in contexts:\n",
    "                        self.learner.learn(k, \n",
    "                                           v['context'],\n",
    "                                           v['action'],\n",
    "                                           sumreward / self.batchsize,\n",
    "                                           v['prob'])\n",
    "                    sumreward = 0\n",
    "                    contexts = []\n",
    "\n",
    "            self.mem = {}\n",
    "\n",
    "\n",
    "class BatchedSuffix:\n",
    "    def __init__(self, delay: int, batchsize: int, learner, reorder=True):\n",
    "        self.learner = learner()\n",
    "        self.batchsize = batchsize\n",
    "        self.delay = delay\n",
    "        self.mem = {}\n",
    "        self.reorder=reorder\n",
    "\n",
    "        assert self.delay % self.batchsize == 0\n",
    "\n",
    "    def init(self):\n",
    "        self.learner.init()\n",
    "\n",
    "    @property\n",
    "    def family(self) -> str:\n",
    "        return \"BatchedSuffix\"\n",
    "\n",
    "    @property\n",
    "    def params(self) -> Dict[str,Any]:\n",
    "        return { \n",
    "                 **self.learner.params,\n",
    "                 **{ 'delay': self.delay, 'batchsize': self.batchsize },\n",
    "               }\n",
    "\n",
    "    def predict(self, key: int, context: Hashable, actions: Sequence[Hashable]) -> int:\n",
    "        \"\"\"Choose which action index to take.\"\"\"\n",
    "        return self.learner.predict(key, context, actions)\n",
    "\n",
    "    def learn(self, key: int, context: Hashable, action: Hashable, reward: float, probability: float) -> None:\n",
    "        \"\"\"Learn about the result of an action that was taken in a context.\"\"\"\n",
    "\n",
    "        self.mem[key] = { 'context': context,\n",
    "                          'action': action,\n",
    "                          'reward': reward,\n",
    "                          'prob': probability\n",
    "                        }\n",
    "\n",
    "        if len(self.mem) >= self.delay:\n",
    "            sumreward = 0\n",
    "            contexts = []\n",
    "            for key, values in self.mem.items():\n",
    "                sumreward += values['reward']\n",
    "                contexts.append((key, values))\n",
    "\n",
    "                if len(contexts) % self.batchsize == 0:\n",
    "                    order = list(range(self.batchsize))\n",
    "                    if self.reorder:\n",
    "                        order = coba.random.shuffle(order) \n",
    "                    for idx, i in enumerate(order):\n",
    "                        (k, v) = contexts[i]\n",
    "                        self.learner.learn(k, \n",
    "                                           v['context'],\n",
    "                                           v['action'],\n",
    "                                           sumreward / (self.batchsize - idx),\n",
    "                                           v['prob'])\n",
    "                        sumreward = sumreward - v['reward']\n",
    "                    sumreward = 0\n",
    "                    contexts = []\n",
    "\n",
    "            self.mem = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Hashable, Sequence, Dict, Any\n",
    "\n",
    "class Advantage:\n",
    "    def __init__(self, seed: int, flags: str, learner):\n",
    "        self.learner = learner()\n",
    "        self.flags = flags\n",
    "        self.seed = seed\n",
    "        self.baseline=None\n",
    "\n",
    "    def init(self):\n",
    "        from os import devnull\n",
    "        from coba import execution\n",
    "\n",
    "        with open(devnull, 'w') as f, execution.redirect_stderr(f):\n",
    "            from vowpalwabbit import pyvw\n",
    "            self.baseline = pyvw.vw(f'--quiet ${self.flags} --random_seed {self.seed}')\n",
    "\n",
    "    def tovw(self, context, reward, prob):\n",
    "        assert type(context) is tuple, context\n",
    "\n",
    "        return '\\n'.join([\n",
    "            f'{reward} {1.0/prob} | ' \n",
    "          + ' '.join([ f'{k+1}:{v}' for k, v in enumerate(context) if v != 0 ])\n",
    "          ])\n",
    "\n",
    "    @property\n",
    "    def family(self) -> str:\n",
    "        return \"Advantage Wrapper\"\n",
    "\n",
    "    @property\n",
    "    def params(self) -> Dict[str,Any]:\n",
    "        return self.learner.params()\n",
    "\n",
    "    def predict(self, key: int, context: Hashable, actions: Sequence[Hashable]) -> int:\n",
    "        return self.learner.predict(key, context, actions)\n",
    "\n",
    "    def learn(self, key: int, context: Hashable, action: Hashable, reward: float, probability: float) -> None:\n",
    "        prob = self.learner._probs[key]\n",
    "        exstr = self.tovw(context, reward, prob)\n",
    "        vhat = self.baseline.predict(exstr)\n",
    "        self.baseline.learn(exstr)\n",
    "        self.learner.learn(key, context, action, reward - vhat, probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_learner(epsilon=0.2, flags='--coin'):\n",
    "    from coba.learners import VowpalLearner\n",
    "    return VowpalLearner(seed=10, epsilon=epsilon, flags=flags)\n",
    "\n",
    "def squarecblearner(epsilon, flags = '--coin'):\n",
    "    from coba.learners import VowpalLearner\n",
    "    return VowpalLearner(seed=10, epsilon = epsilon, flags=f'--squarecb {flags}')\n",
    "\n",
    "def synthcoverlearner(epsilon, flags = '--coin'):\n",
    "    from coba.learners import VowpalLearner\n",
    "    return VowpalLearner(seed=10, epsilon=epsilon, flags=f'--synthcover {flags}')\n",
    "\n",
    "def baglearner(bag=5, flags='--coin'):\n",
    "    from coba.learners import VowpalLearner\n",
    "    return VowpalLearner(seed=10, bag=bag, flags=flags)    \n"
   ]
  },
  {
   "source": [
    "# Simulation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coba.random\n",
    "\n",
    "from coba.simulations import LambdaSimulation\n",
    "from coba.learners.bandit import RandomLearner, EpsilonBanditLearner, UcbBanditLearner\n",
    "from coba.learners.vowpal import VowpalLearner\n",
    "from coba.benchmarks import Benchmark\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from coba.benchmarks import Benchmark\n",
    "import re\n",
    "\n",
    "def get_context(means, t):\n",
    "    return (str(t % means.shape[0]), str(coba.random.randint(0, means.shape[1] - 1)))\n",
    "\n",
    "def get_actions(means):\n",
    "    return [str(i) for i in range(means.shape[2])]\n",
    "\n",
    "def get_reward(means, c, a):\n",
    "    return int(coba.random.random() < means[int(c[0])][int(c[1])][int(a)]) \n",
    "\n",
    "def print_info(title, means, epsilon=0.2):\n",
    "    random_perf = np.mean(means)\n",
    "    best_perf = np.max(means, axis=2).mean()\n",
    "\n",
    "    print(f'----{title}----')\n",
    "    print(f'Random perfomance: {random_perf}')\n",
    "    print(f'Best performance: {best_perf}')\n",
    "    print(f'Best performance with {epsilon} exploration: {best_perf * (1 - epsilon) + random_perf * epsilon}')"
   ]
  },
  {
   "source": [
    "# Experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_the_test(means, count, batched, batchsize, learners, baseline=VowpalLearner(epsilon=0.2, seed=10, flags='--coin'), delay=8):\n",
    "    actions_objects = get_actions(means)\n",
    "\n",
    "    contexts = lambda t: get_context(means, t)\n",
    "    actions = lambda t, c: actions_objects\n",
    "\n",
    "    rewards = lambda t, c, a: get_reward(means, c, a)\n",
    "\n",
    "    #define a simulation\n",
    "    simulations = [\n",
    "        LambdaSimulation(count, contexts, actions, rewards, seed=10),\n",
    "    ]\n",
    "\n",
    "    #define a benchmark: this benchmark replays the simulation 15 times\n",
    "    benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "    learner_factories = [baseline] + [batched(delay=delay, batchsize=batchsize, learner=l) for l in learners]\n",
    "\n",
    "    return benchmark.evaluate(learner_factories)"
   ]
  },
  {
   "source": [
    "## Simulations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 1\n",
    "npeople = 8\n",
    "nactions = 8\n",
    "\n",
    "means_1_8_8 = np.ndarray(shape = (nsteps, npeople, nactions), buffer = np.array(coba.random.randoms(nsteps * npeople * nactions)))\n",
    "print_info('means_1_8_8', means_1_8_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners = [\n",
    "    lambda: epsilon_greedy_learner(epsilon=0.2),\n",
    "    lambda: squarecblearner(epsilon=0.01),\n",
    "    lambda: baglearner(),\n",
    "    lambda: synthcoverlearner(epsilon=0.01)]"
   ]
  },
  {
   "source": [
    "# Episodic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## steps = 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_the_test(means_1_8_8, count, Batched, 1, learners, baseline=epsilon_greedy_learner())\n",
    "result.standard_plot(show_err=True, figsize=[16,6], episode_factor=1)"
   ]
  },
  {
   "source": [
    "## steps = 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_the_test(means_1_8_8, count, Batched, 2, learners, baseline=epsilon_greedy_learner())\n",
    "result.standard_plot(show_err=True, figsize=[16,6], episode_factor=1)"
   ]
  },
  {
   "source": [
    "## steps = 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_the_test(means_1_8_8, count, Batched, 4, learners, baseline=epsilon_greedy_learner())\n",
    "result.standard_plot(show_err=True, figsize=[16,6], episode_factor=1)"
   ]
  },
  {
   "source": [
    "## steps = 8"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_the_test(means_1_8_8, count, Batched, 8, learners, baseline=epsilon_greedy_learner())\n",
    "result.standard_plot(show_err=True, figsize=[16,6], episode_factor=1)"
   ]
  },
  {
   "source": [
    "# Suffix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## steps = 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_the_test(means_1_8_8, count, BatchedSuffix, 1, learners, baseline=epsilon_greedy_learner())\n",
    "result.standard_plot(show_err=True, figsize=[16,6], episode_factor=2)"
   ]
  },
  {
   "source": [
    "## steps = 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_the_test(means_1_8_8, count, BatchedSuffix, 2, learners, baseline=epsilon_greedy_learner())\n",
    "result.standard_plot(show_err=True, figsize=[16,6], episode_factor=2)"
   ]
  },
  {
   "source": [
    "## steps = 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_the_test(means_1_8_8, count, BatchedSuffix, 4, learners, baseline=epsilon_greedy_learner())\n",
    "result.standard_plot(show_err=True, figsize=[16,6], episode_factor=2)"
   ]
  },
  {
   "source": [
    "## steps = 8"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_the_test(means_1_8_8, count, BatchedSuffix, 8, learners, baseline=epsilon_greedy_learner())\n",
    "result.standard_plot(show_err=True, figsize=[16,6], episode_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}