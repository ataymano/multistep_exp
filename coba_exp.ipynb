{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Learners"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Paul's stuff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Hashable, Sequence, Dict, Any\n",
    "import coba.random\n",
    "\n",
    "class Batched:\n",
    "    def __init__(self, delay: int, batchsize: int, learner):\n",
    "        self.learner = learner()\n",
    "        self.batchsize = batchsize\n",
    "        self.delay = delay\n",
    "        self.mem = {}\n",
    "\n",
    "        assert self.delay % self.batchsize == 0\n",
    "\n",
    "    def init(self):\n",
    "        self.learner.init()\n",
    "\n",
    "    @property\n",
    "    def family(self) -> str:\n",
    "        return \"Batched Learner\"\n",
    "\n",
    "    @property\n",
    "    def params(self) -> Dict[str,Any]:\n",
    "        return { \n",
    "                 #**self.learner.params(),\n",
    "                 **{ 'delay': self.delay, 'batchsize': self.batchsize },\n",
    "               }\n",
    "\n",
    "    def predict(self, key: int, context: Hashable, actions: Sequence[Hashable]) -> int:\n",
    "        \"\"\"Choose which action index to take.\"\"\"\n",
    "        return self.learner.predict(key, context, actions)\n",
    "\n",
    "    def learn(self, key: int, context: Hashable, action: Hashable, reward: float, probability: float) -> None:\n",
    "        \"\"\"Learn about the result of an action that was taken in a context.\"\"\"\n",
    "\n",
    "        self.mem[key] = { 'context': context,\n",
    "                          'action': action,\n",
    "                          'reward': reward,\n",
    "                          'prob': probability\n",
    "                        }\n",
    "\n",
    "        if len(self.mem) >= self.delay:\n",
    "            sumreward = 0\n",
    "            contexts = []\n",
    "            for key, values in self.mem.items():\n",
    "                sumreward += values['reward']\n",
    "                contexts.append((key, values))\n",
    "\n",
    "                if len(contexts) % self.batchsize == 0:\n",
    "                    for k, v in contexts:\n",
    "                        self.learner.learn(k, \n",
    "                                           v['context'],\n",
    "                                           v['action'],\n",
    "                                           sumreward / self.batchsize,\n",
    "                                           v['prob'])\n",
    "                    sumreward = 0\n",
    "                    contexts = []\n",
    "\n",
    "            self.mem = {}\n",
    "\n",
    "\n",
    "class BatchedSuffix:\n",
    "    def __init__(self, delay: int, batchsize: int, learner, reorder=True):\n",
    "        self.learner = learner()\n",
    "        self.batchsize = batchsize\n",
    "        self.delay = delay\n",
    "        self.mem = {}\n",
    "        self.reorder=reorder\n",
    "\n",
    "        assert self.delay % self.batchsize == 0\n",
    "\n",
    "    def init(self):\n",
    "        self.learner.init()\n",
    "\n",
    "    @property\n",
    "    def family(self) -> str:\n",
    "        return \"Batched Learner\"\n",
    "\n",
    "    @property\n",
    "    def params(self) -> Dict[str,Any]:\n",
    "        return { \n",
    "                 #**self.learner.params(),\n",
    "                 **{ 'delay': self.delay, 'batchsize': self.batchsize },\n",
    "               }\n",
    "\n",
    "    def predict(self, key: int, context: Hashable, actions: Sequence[Hashable]) -> int:\n",
    "        \"\"\"Choose which action index to take.\"\"\"\n",
    "        return self.learner.predict(key, context, actions)\n",
    "\n",
    "    def learn(self, key: int, context: Hashable, action: Hashable, reward: float, probability: float) -> None:\n",
    "        \"\"\"Learn about the result of an action that was taken in a context.\"\"\"\n",
    "\n",
    "        self.mem[key] = { 'context': context,\n",
    "                          'action': action,\n",
    "                          'reward': reward,\n",
    "                          'prob': probability\n",
    "                        }\n",
    "\n",
    "        if len(self.mem) >= self.delay:\n",
    "            sumreward = 0\n",
    "            contexts = []\n",
    "            for key, values in self.mem.items():\n",
    "                sumreward += values['reward']\n",
    "                contexts.append((key, values))\n",
    "\n",
    "                if len(contexts) % self.batchsize == 0:\n",
    "                    order = list(range(self.batchsize))\n",
    "                    if self.reorder:\n",
    "                        order = coba.random.shuffle(order) \n",
    "                    for idx, i in enumerate(order):\n",
    "                        (k, v) = contexts[i]\n",
    "                        self.learner.learn(k, \n",
    "                                           v['context'],\n",
    "                                           v['action'],\n",
    "                                           sumreward / (self.batchsize - idx),\n",
    "                                           v['prob'])\n",
    "                        sumreward = sumreward - v['reward']\n",
    "                    sumreward = 0\n",
    "                    contexts = []\n",
    "\n",
    "            self.mem = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Hashable, Sequence, Dict, Any\n",
    "\n",
    "class Advantage:\n",
    "    def __init__(self, seed: int, flags: str, learner):\n",
    "        self.learner = learner()\n",
    "        self.flags = flags\n",
    "        self.seed = seed\n",
    "        self.baseline=None\n",
    "\n",
    "    def init(self):\n",
    "        from os import devnull\n",
    "        from coba import execution\n",
    "\n",
    "        with open(devnull, 'w') as f, execution.redirect_stderr(f):\n",
    "            from vowpalwabbit import pyvw\n",
    "            self.baseline = pyvw.vw(f'--quiet ${self.flags} --random_seed {self.seed}')\n",
    "\n",
    "    def tovw(self, context, reward, prob):\n",
    "        assert type(context) is tuple, context\n",
    "\n",
    "        return '\\n'.join([\n",
    "            f'{reward} {1.0/prob} | ' \n",
    "          + ' '.join([ f'{k+1}:{v}' for k, v in enumerate(context) if v != 0 ])\n",
    "          ])\n",
    "\n",
    "    @property\n",
    "    def family(self) -> str:\n",
    "        return \"Advantage Wrapper\"\n",
    "\n",
    "    @property\n",
    "    def params(self) -> Dict[str,Any]:\n",
    "        return self.learner.params()\n",
    "\n",
    "    def predict(self, key: int, context: Hashable, actions: Sequence[Hashable]) -> int:\n",
    "        return self.learner.predict(key, context, actions)\n",
    "\n",
    "    def learn(self, key: int, context: Hashable, action: Hashable, reward: float, probability: float) -> None:\n",
    "        prob = self.learner._probs[key]\n",
    "        exstr = self.tovw(context, reward, prob)\n",
    "        vhat = self.baseline.predict(exstr)\n",
    "        self.baseline.learn(exstr)\n",
    "        self.learner.learn(key, context, action, reward - vhat, probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseLearner(epsilon=0.2, flags='--coin'):\n",
    "    from coba.learners import VowpalLearner\n",
    "    return VowpalLearner(seed=10, epsilon=epsilon, flags=flags)\n",
    "\n",
    "def squarecblearner(epsilon, flags = '--coin'):\n",
    "    from coba.learners import VowpalLearner\n",
    "    return VowpalLearner(seed=10, epsilon = epsilon, flags=f'--squarecb {flags}')\n",
    "\n",
    "def synthcoverlearner(epsilon, flags=''):\n",
    "    from coba.learners import VowpalLearner\n",
    "    return VowpalLearner(seed=10, epsilon=epsilon, flags=f'--synthcover {flags}')\n",
    "\n",
    "def baglearner(flags, bag=5):\n",
    "    from coba.learners import VowpalLearner\n",
    "    return VowpalLearner(seed=10, bag=bag, flags=flags)    \n",
    "\n",
    "#def vwlearner(flags):\n",
    "#    from coba.learners import VowpalLearner\n",
    "#    return VowpalLearner(seed=10, flags=flags)\n",
    "\n",
    "#def advantageLearner():\n",
    "#    return Advantage(seed=10, flags='--coin', learner=baseLearner)"
   ]
  },
  {
   "source": [
    "# Simulation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coba.random\n",
    "\n",
    "from coba.simulations import LambdaSimulation\n",
    "from coba.learners.bandit import RandomLearner, EpsilonBanditLearner, UcbBanditLearner\n",
    "from coba.learners.vowpal import VowpalLearner\n",
    "from coba.benchmarks import Benchmark\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from coba.benchmarks import Benchmark\n",
    "import re\n",
    "\n",
    "def get_context(means, t):\n",
    "    return (str(t % means.shape[0]), str(coba.random.randint(0, means.shape[1] - 1)))\n",
    "\n",
    "def get_actions(means):\n",
    "    return [str(i) for i in range(means.shape[2])]\n",
    "\n",
    "def get_reward(means, c, a):\n",
    "    return int(coba.random.random() < means[int(c[0])][int(c[1])][int(a)]) \n",
    "\n",
    "def print_info(title, means, epsilon=0.2):\n",
    "    random_perf = np.mean(means)\n",
    "    best_perf = np.max(means, axis=2).mean()\n",
    "\n",
    "    print(f'----{title}----')\n",
    "    print(f'Random perfomance: {random_perf}')\n",
    "    print(f'Best performance: {best_perf}')\n",
    "    print(f'Best performance with {epsilon} exploration: {best_perf * (1 - epsilon) + random_perf * epsilon}')"
   ]
  },
  {
   "source": [
    "# Experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoTheTest(means, count, batched, learner=baseLearner, baseline=VowpalLearner(epsilon=0.2, seed=10, flags='--coin')):\n",
    "    actions_objects = get_actions(means)\n",
    "\n",
    "    contexts = lambda t: get_context(means, t)\n",
    "    actions = lambda t, c: actions_objects\n",
    "\n",
    "    rewards = lambda t, c, a: get_reward(means, c, a)\n",
    "\n",
    "    #define a simulation\n",
    "    simulations = [\n",
    "        LambdaSimulation(count, contexts, actions, rewards, seed=10),\n",
    "    ]\n",
    "\n",
    "    #define a benchmark: this benchmark replays the simulation 15 times\n",
    "    benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "    #create the learner factories\n",
    "    learner_factories = [\n",
    "    #    RandomLearner(seed=10),\n",
    "        baseline,\n",
    "        batched(delay=8, batchsize=1, learner=learner),\n",
    "        batched(delay=8, batchsize=2, learner=learner),\n",
    "        batched(delay=8, batchsize=4, learner=learner),\n",
    "        batched(delay=8, batchsize=8, learner=learner),\n",
    "    ]\n",
    "\n",
    "    return benchmark.evaluate(learner_factories)"
   ]
  },
  {
   "source": [
    "## Simulations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 1\n",
    "npeople = 8\n",
    "nactions = 8\n",
    "\n",
    "means_1_8_8 = np.ndarray(shape = (nsteps, npeople, nactions), buffer = np.array(coba.random.randoms(nsteps * npeople * nactions)))\n",
    "print_info('means_1_8_8', means_1_8_8)\n",
    "\n",
    "means_2_4_8 = means_1_8_8.reshape(2,4,8)\n",
    "print_info('means_2_4_8', means_2_4_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=10000"
   ]
  },
  {
   "source": [
    "# Epsilon-greedy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = DoTheTest(means_1_8_8, count, Batched, learner=lambda: baseLearner(), baseline=baseLearner())\n",
    "result.standard_plot(show_err=True, figsize=[16,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "result = DoTheTest(means_1_8_8, count, BatchedSuffix, learner=lambda: baseLearner(), baseline=baseLearner())\n",
    "result.standard_plot(show_err=True)\n",
    "#Plots.standard_plot(result, episode_factor=2, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.standard_plot(result, episode_factor=2, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "result = DoTheTest(means_2_4_8, count, Batched, learner=lambda: baseLearner(), baseline=baseLearner())\n",
    "Plots.standard_plot(result, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "result = DoTheTest(means_2_4_8, count, BatchedSuffix, learner=lambda: baseLearner(), baseline=baseLearner())\n",
    "Plots.standard_plot(result, episode_factor=2, show_err=True)"
   ]
  },
  {
   "source": [
    "# SquareCB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags='--squarecb --coin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "result = DoTheTest(means_1_8_8, count, Batched, learner=lambda: squarecblearner(epsilon=0.025), baseline=squarecblearner(epsilon=0.025))\n",
    "Plots.standard_plot(result, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "result = DoTheTest(means_1_8_8, count, BatchedSuffix, learner=lambda: squarecblearner(epsilon=0.025), baseline=squarecblearner(epsilon=0.025))\n",
    "Plots.standard_plot(result, episode_factor=2, show_err=True)"
   ]
  },
  {
   "source": [
    "# Bag"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "result = DoTheTest(means_1_8_8, count, Batched, learner=lambda : baglearner('--epsilon 0.05 --coin'), baseline=baglearner('--epsilon 0.05 --coin'))\n",
    "Plots.standard_plot(result, episode_factor=1, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "result = DoTheTest(means_1_8_8, count, BatchedSuffix, learner=lambda : baglearner('--epsilon 0.05 --coin'), baseline=baglearner('--epsilon 0.05 --coin'))\n",
    "Plots.standard_plot(result, episode_factor=2, show_err=True)"
   ]
  },
  {
   "source": [
    "# SynthCover"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "result = DoTheTest(means_1_8_8, count, Batched, learner=lambda: synthcoverlearner(epsilon=0.01), baseline=synthcoverlearner(epsilon=0.01))\n",
    "Plots.standard_plot(result, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "result_suf = DoTheTest(means_1_8_8, count, BatchedSuffix, learner=lambda: synthcoverlearner(epsilon=0.01), baseline=synthcoverlearner(epsilon=0.01))\n",
    "Plots.standard_plot(result_suf, episode_factor=2, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "means = means_2_4_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(100000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "#    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10, flags='--coin'),\n",
    "    Batched(delay=8, batchsize=1, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=baseLearner),\n",
    "]\n",
    "\n",
    "result = benchmark.evaluate(learner_factories)\n",
    "Plots.standard_plot(result, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "means = means_1_8_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(10000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10),\n",
    "    Batched(delay=8, batchsize=1, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=advantageLearner),\n",
    "]\n",
    "\n",
    "benchmark.evaluate(learner_factories).standard_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = means_2_4_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(10000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10),\n",
    "    Batched(delay=8, batchsize=1, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=baseLearner),\n",
    "]\n",
    "\n",
    "benchmark.evaluate(learner_factories).standard_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = means_2_4_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(10000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10),\n",
    "    Batched(delay=8, batchsize=1, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=advantageLearner),\n",
    "]\n",
    "\n",
    "benchmark.evaluate(learner_factories).standard_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = means_8_1_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(10000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10),\n",
    "    Batched(delay=8, batchsize=1, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=baseLearner),\n",
    "]\n",
    "\n",
    "benchmark.evaluate(learner_factories).standard_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "mylist = list(range(5))\n",
    "res=random.shuffle(mylist)\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coba.random\n",
    "coba.random.shuffle([\"1\",\"2\",\"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.s"
   ]
  }
 ]
}