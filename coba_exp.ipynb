{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36564bitbasecondad44845cb0df0418986ceeb24f570a602",
   "display_name": "Python 3.6.5 64-bit ('base': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'grep' is not recognized as an internal or external command,\noperable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "from coba.benchmarks import Result\n",
    "#from coba.analysis import Plots\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [12.0, 9.0]\n",
    "! pip list | grep coba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plots():\n",
    "\n",
    "    @staticmethod\n",
    "    def standard_plot(result: Result, episode_factor: int = 1, show_err: bool = False, show_sd: bool = False) -> None:\n",
    "        from collections import defaultdict\n",
    "        from itertools import groupby \n",
    "        from typing import cast, Dict, List\n",
    "        import math\n",
    "        from coba.utilities import check_matplotlib_support\n",
    "        from coba.benchmarks import Result\n",
    "        from coba.statistics import OnlineMean, OnlineVariance\n",
    "\n",
    "        def _plot(axes, label, xs, ys, vs, ns):\n",
    "            axes.plot(xs, ys, label=label)\n",
    "\n",
    "            if show_sd:\n",
    "                ls = [ y-math.sqrt(v) for y,v in zip(ys,vs) ]\n",
    "                us = [ y+math.sqrt(v) for y,v in zip(ys,vs) ]\n",
    "                axes.fill_between(xs, ls, us, alpha = 0.1)\n",
    "\n",
    "            if show_err:\n",
    "                # I don't really understand what this is... For each x our distribution\n",
    "                # is changing so its VAR is also changing. What does it mean to calculate\n",
    "                # sample variance from a deterministic collection of random variables with\n",
    "                # different distributions? For example sample variance of 10 random variables\n",
    "                # from dist1 and 10 random variables from dist2... This is not the same as 20\n",
    "                # random variables with 50% chance drawing from dist1 and 50% chance of drawing\n",
    "                # from dist2. So the distribution can only be defined over the whole space (i.e.,\n",
    "                # all 20 random variables) and not for a specific random variable. Oh well, for\n",
    "                # now I'm leaving this as it is since I don't have any better ideas. I think what\n",
    "                # I've done is ok, but I need to more some more thought into it.\n",
    "                ls = [ y-math.sqrt(v/n) for y,v,n in zip(ys,vs,ns) ]\n",
    "                us = [ y+math.sqrt(v/n) for y,v,n in zip(ys,vs,ns) ]\n",
    "                axes.fill_between(xs, ls, us, alpha = 0.1)\n",
    "\n",
    "        learners, _, batches = result.to_indexed_tuples()\n",
    "\n",
    "        learner_index_key = lambda batch: (batch.learner_id, batch.batch_index)\n",
    "        sorted_batches    = sorted(batches.values(), key=learner_index_key)\n",
    "        grouped_batches   = groupby(groupby(sorted_batches , key=learner_index_key), key=lambda x: x[0][0])\n",
    "\n",
    "        max_batch_N = 0\n",
    "\n",
    "        indexes     = cast(Dict[int,List[int  ]], defaultdict(list))\n",
    "        incounts    = cast(Dict[int,List[int  ]], defaultdict(list))\n",
    "        inmeans     = cast(Dict[int,List[float]], defaultdict(list))\n",
    "        invariances = cast(Dict[int,List[float]], defaultdict(list))\n",
    "        cucounts    = cast(Dict[int,List[int  ]], defaultdict(list))\n",
    "        cumeans     = cast(Dict[int,List[float]], defaultdict(list))\n",
    "        cuvariances = cast(Dict[int,List[float]], defaultdict(list))\n",
    "\n",
    "        for learner_id, learner_batches in grouped_batches:\n",
    "\n",
    "            cucount    = 0\n",
    "            cumean     = OnlineMean()\n",
    "            cuvariance = OnlineVariance()\n",
    "\n",
    "            for (_, batch_index), index_batches in learner_batches:\n",
    "\n",
    "                incount    = 0\n",
    "                inmean     = OnlineMean()\n",
    "                invariance = OnlineVariance()\n",
    "\n",
    "                for N, reward in [ (b.N, b.reward) for b in index_batches]:\n",
    "\n",
    "                    max_batch_N = max(N, max_batch_N)\n",
    "\n",
    "                    incount     = incount + 1\n",
    "                    inmean      .update(reward)\n",
    "                    invariance  .update(reward)\n",
    "                    cucount     = cucount + 1\n",
    "                    cumean      .update(reward)\n",
    "                    cuvariance  .update(reward)\n",
    "\n",
    "                #sanity check, sorting above (in theory) should take care of this...\n",
    "                #if this isn't the case then the cu* values will be incorrect...\n",
    "                assert indexes[learner_id] == [] or batch_index > indexes[learner_id][-1]\n",
    "\n",
    "                incounts[learner_id].append(incount)\n",
    "                indexes[learner_id].append(batch_index)\n",
    "                inmeans[learner_id].append(inmean.mean)\n",
    "                invariances[learner_id].append(invariance.variance)\n",
    "                cucounts[learner_id].append(cucount)\n",
    "                cumeans[learner_id].append(cumean.mean)\n",
    "                cuvariances[learner_id].append(cuvariance.variance)\n",
    "\n",
    "        check_matplotlib_support('Plots.standard_plot')\n",
    "        import matplotlib.pyplot as plt #type: ignore\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        index_unit = \"Interaction\" if max_batch_N ==1 else \"Batch\"\n",
    "\n",
    "        ax1 = fig.add_subplot(1,2,1) \n",
    "        ax2 = fig.add_subplot(1,2,2) \n",
    "\n",
    "#         for learner_id in learners:\n",
    "#             _plot(ax1, learners[learner_id].full_name, indexes[learner_id], inmeans[learner_id], invariances[learner_id], incounts[learner_id])\n",
    "        ax1.set_title(\"Progressive Average Reward\")\n",
    "#         ax1.set_ylabel(\"Mean Reward\")\n",
    "        ax1.set_ylabel('reward (averaged over datasets)')\n",
    "        ax1.set_xlabel(f\"episodes / {episode_factor}\")\n",
    "\n",
    "        for learner_id in learners:\n",
    "            batch_size = 1\n",
    "            if learner_id > 0:\n",
    "                batch_size = learners[learner_id].batchsize\n",
    "            if batch_size != 1:\n",
    "                batch_size = batch_size / episode_factor\n",
    "            _plot(ax1, learners[learner_id].full_name, np.divide(indexes[learner_id], batch_size), cumeans[learner_id], cuvariances[learner_id], cucounts[learner_id])\n",
    "            _plot(ax2, learners[learner_id].full_name, indexes[learner_id], cumeans[learner_id], cuvariances[learner_id], cucounts[learner_id])\n",
    "\n",
    "\n",
    "        ax2.set_title(\"Progressive Average Reward\")\n",
    "#         ax1.set_xlabel(f\"{index_unit} Index\")\n",
    "\n",
    "#         (bot1, top1) = ax1.get_ylim()\n",
    "        (bot2, top2) = ax2.get_ylim()\n",
    "\n",
    "#         ax1.set_ylim(min(bot1,bot2), max(top1,top2))\n",
    "#         ax2.set_ylim(min(bot1,bot2), max(top1,top2))\n",
    "\n",
    "        scale = 0.25\n",
    "#         box1 = ax1.get_position()\n",
    "        box2 = ax2.get_position()\n",
    "#         ax1.set_position([box1.x0, box1.y0 + box1.height * scale, box1.width, box1.height * (1-scale)])\n",
    "#         ax2.set_position([box2.x0, box2.y0 + box2.height * scale, box2.width, box2.height * (1-scale)])\n",
    "\n",
    "        # Put a legend below current axis\n",
    "#         fig.legend(*ax2.get_legend_handles_labels(), loc='upper center', bbox_to_anchor=(.5, .175), fancybox=True, ncol=2) #type: ignore\n",
    "        ax2.set_xlabel('examples')\n",
    "        ax2.set_ylabel('reward (averaged over datasets)')\n",
    "        ax2.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "source": [
    "# Learners"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Paul's stuff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Hashable, Sequence, Dict, Any\n",
    "import coba.random\n",
    "\n",
    "class Batched:\n",
    "    def __init__(self, delay: int, batchsize: int, learner):\n",
    "        self.learner = learner()\n",
    "        self.batchsize = batchsize\n",
    "        self.delay = delay\n",
    "        self.mem = {}\n",
    "\n",
    "        assert self.delay % self.batchsize == 0\n",
    "\n",
    "    def init(self):\n",
    "        self.learner.init()\n",
    "\n",
    "    @property\n",
    "    def family(self) -> str:\n",
    "        return \"Batched Learner\"\n",
    "\n",
    "    @property\n",
    "    def params(self) -> Dict[str,Any]:\n",
    "        return { \n",
    "                 #**self.learner.params(),\n",
    "                 **{ 'delay': self.delay, 'batchsize': self.batchsize },\n",
    "               }\n",
    "\n",
    "    def choose(self, key: int, context: Hashable, actions: Sequence[Hashable]) -> int:\n",
    "        \"\"\"Choose which action index to take.\"\"\"\n",
    "        return self.learner.choose(key, context, actions)\n",
    "\n",
    "    def learn(self, key: int, context: Hashable, action: Hashable, reward: float) -> None:\n",
    "        \"\"\"Learn about the result of an action that was taken in a context.\"\"\"\n",
    "\n",
    "        self.mem[key] = { 'context': context,\n",
    "                          'action': action,\n",
    "                          'reward': reward\n",
    "                        }\n",
    "\n",
    "        if len(self.mem) >= self.delay:\n",
    "            sumreward = 0\n",
    "            contexts = []\n",
    "            for key, values in self.mem.items():\n",
    "                sumreward += values['reward']\n",
    "                contexts.append((key, values))\n",
    "\n",
    "                if len(contexts) % self.batchsize == 0:\n",
    "                    order = coba.random.shuffle(list(range(self.batchsize)))\n",
    "                    for idx, i in enumerate(order):\n",
    "                        (k, v) = contexts[i]\n",
    "                        self.learner.learn(k, \n",
    "                                           v['context'],\n",
    "                                           v['action'],\n",
    "                                           sumreward / (self.batchsize - idx))\n",
    "                        sumreward = sumreward - v['reward']\n",
    "                    sumreward = 0\n",
    "                    contexts = []\n",
    "\n",
    "            self.mem = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Hashable, Sequence, Dict, Any\n",
    "\n",
    "class Advantage:\n",
    "    def __init__(self, seed: int, flags: str, learner):\n",
    "        self.learner = learner()\n",
    "        self.flags = flags\n",
    "        self.seed = seed\n",
    "        self.baseline=None\n",
    "\n",
    "    def init(self):\n",
    "        from os import devnull\n",
    "        from coba import execution\n",
    "\n",
    "        with open(devnull, 'w') as f, execution.redirect_stderr(f):\n",
    "            from vowpalwabbit import pyvw\n",
    "            self.baseline = pyvw.vw(f'--quiet ${self.flags} --random_seed {self.seed}')\n",
    "\n",
    "    def tovw(self, context, reward, prob):\n",
    "        assert type(context) is tuple, context\n",
    "\n",
    "        return '\\n'.join([\n",
    "            f'{reward} {1.0/prob} | ' \n",
    "          + ' '.join([ f'{k+1}:{v}' for k, v in enumerate(context) if v != 0 ])\n",
    "          ])\n",
    "\n",
    "    @property\n",
    "    def family(self) -> str:\n",
    "        return \"Advantage Wrapper\"\n",
    "\n",
    "    @property\n",
    "    def params(self) -> Dict[str,Any]:\n",
    "        return self.learner.params()\n",
    "\n",
    "    def choose(self, key: int, context: Hashable, actions: Sequence[Hashable]) -> int:\n",
    "        return self.learner.choose(key, context, actions)\n",
    "\n",
    "    def learn(self, key: int, context: Hashable, action: Hashable, reward: float) -> None:\n",
    "        prob = self.learner._probs[key]\n",
    "        exstr = self.tovw(context, reward, prob)\n",
    "        vhat = self.baseline.predict(exstr)\n",
    "        self.baseline.learn(exstr)\n",
    "        self.learner.learn(key, context, action, reward - vhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseLearner():\n",
    "    from coba.learners import VowpalLearner\n",
    "    return VowpalLearner(seed=10, epsilon=0.2, flags='--coin')\n",
    "\n",
    "def advantageLearner():\n",
    "    return Advantage(seed=10, flags='--coin', learner=baseLearner)"
   ]
  },
  {
   "source": [
    "# Simulation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coba.random\n",
    "\n",
    "from coba.simulations import LambdaSimulation\n",
    "from coba.learners import RandomLearner, EpsilonLearner, VowpalLearner, UcbTunedLearner\n",
    "from coba.benchmarks import Benchmark\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from coba.benchmarks import Benchmark\n",
    "import re\n",
    "\n",
    "def get_context(means, t):\n",
    "    return (str(t % means.shape[0]), str(coba.random.randint(0, means.shape[1] - 1)))\n",
    "\n",
    "def get_actions(means):\n",
    "    return [str(i) for i in range(means.shape[2])]\n",
    "\n",
    "def get_reward(means, c, a):\n",
    "    return int(coba.random.random() < means[int(c[0])][int(c[1])][int(a)]) \n",
    "\n",
    "def print_info(title, means, epsilon=0.2):\n",
    "    random_perf = np.mean(means)\n",
    "    best_perf = np.max(means, axis=2).mean()\n",
    "\n",
    "    print(f'----{title}----')\n",
    "    print(f'Random perfomance: {random_perf}')\n",
    "    print(f'Best performance: {best_perf}')\n",
    "    print(f'Best performance with {epsilon} exploration: {best_perf * (1 - epsilon) + random_perf * epsilon}')"
   ]
  },
  {
   "source": [
    "# Experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Simulations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----means_1_8_8----\nRandom perfomance: 0.4696920402065776\nBest performance: 0.9034116238154579\nBest performance with 0.2 exploration: 0.8166677070936819\n----means_2_4_8----\nRandom perfomance: 0.4696920402065776\nBest performance: 0.9034116238154579\nBest performance with 0.2 exploration: 0.8166677070936819\n"
     ]
    }
   ],
   "source": [
    "nsteps = 1\n",
    "npeople = 8\n",
    "nactions = 8\n",
    "\n",
    "means_1_8_8 = np.ndarray(shape = (nsteps, npeople, nactions), buffer = np.array(coba.random.randoms(nsteps * npeople * nactions)))\n",
    "print_info('means_1_8_8', means_1_8_8)\n",
    "\n",
    "means_2_4_8 = means_1_8_8.reshape(2,4,8)\n",
    "print_info('means_2_4_8', means_2_4_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----means_8_1_8----\nRandom perfomance: 0.4696920402065776\nBest performance: 0.9034116238154579\nBest performance with 0.2 exploration: 0.8166677070936819\n"
     ]
    }
   ],
   "source": [
    "means_8_1_8 = means_1_8_8.reshape(8,1,8)\n",
    "print_info('means_8_1_8', means_8_1_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-12-14 09:00:14 loading simulation...\n2020-12-14 09:00:14   * finished after 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "means = means_1_8_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(100000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "#    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10, flags='--coin'),\n",
    "    Batched(delay=8, batchsize=1, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=baseLearner),\n",
    "]\n",
    "\n",
    "result = benchmark.evaluate(learner_factories)\n",
    "Plots.standard_plot(result, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.standard_plot(result, episode_factor=2, show_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-12-01 01:11:43 loading simulation...\n2020-12-01 01:11:43   * finished after 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "means = means_1_8_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(10000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10),\n",
    "    Batched(delay=8, batchsize=1, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=advantageLearner),\n",
    "]\n",
    "\n",
    "benchmark.evaluate(learner_factories).standard_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-11-30 12:51:58 loading simulation...\n2020-11-30 12:51:58   * finished after 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "means = means_2_4_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(10000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10),\n",
    "    Batched(delay=8, batchsize=1, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=baseLearner),\n",
    "]\n",
    "\n",
    "benchmark.evaluate(learner_factories).standard_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-11-30 12:56:31 loading simulation...\n2020-11-30 12:56:31   * finished after 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "means = means_2_4_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(10000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10),\n",
    "    Batched(delay=8, batchsize=1, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=advantageLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=advantageLearner),\n",
    "]\n",
    "\n",
    "benchmark.evaluate(learner_factories).standard_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-11-30 13:22:49 loading simulation...\n2020-11-30 13:22:49   * finished after 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "means = means_8_1_8\n",
    "\n",
    "actions_objects = get_actions(means)\n",
    "\n",
    "contexts = lambda t: get_context(means, t)\n",
    "actions = lambda t: actions_objects\n",
    "\n",
    "rewards = lambda c, a: get_reward(means, c, a)\n",
    "\n",
    "#define a simulation\n",
    "simulations = [\n",
    "    LambdaSimulation(10000, contexts, actions, rewards, seed=10),\n",
    "]\n",
    "\n",
    "#define a benchmark: this benchmark replays the simulation 15 times\n",
    "benchmark = Benchmark(simulations, batch_size = 1, shuffle_seeds=list(range(5)))\n",
    "\n",
    "#create the learner factories\n",
    "learner_factories = [\n",
    "    RandomLearner(seed=10),\n",
    "    VowpalLearner(epsilon=0.2, seed=10),\n",
    "    Batched(delay=8, batchsize=1, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=2, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=4, learner=baseLearner),\n",
    "    Batched(delay=8, batchsize=8, learner=baseLearner),\n",
    "]\n",
    "\n",
    "benchmark.evaluate(learner_factories).standard_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[4, 1, 2, 0, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "import random\n",
    "mylist = list(range(5))\n",
    "res=random.shuffle(mylist)\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['3', '1', '2']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import coba.random\n",
    "coba.random.shuffle([\"1\",\"2\",\"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.s"
   ]
  }
 ]
}